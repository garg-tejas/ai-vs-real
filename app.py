import streamlit as st
import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
from torchvision import transforms
from pathlib import Path
import time
import os
from huggingface_hub import hf_hub_download

from models.resnet_model import build_resnet
from models.efficientnet_model import build_efficientnet
from models.convnext_model import build_convnext
from models.coatnet_model import build_coatnet
from models.hybrid_vit_model import build_hybrid_vit

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
NUM_CLASSES = 2
IMAGE_SIZE = 224
CLASSES = ["Real Image", "AI-Generated Image"]

HF_REPO_ID = "ggtejas/ai-vs-real-models"

st.set_page_config(
    page_title="AI vs Real Image Classifier",
    page_icon="üñºÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded",
)

@st.cache_resource
def load_models():
    """Load all five models with their best accuracy checkpoints from Hugging Face"""
    models = {}
    model_builders = {
        "ResNet": build_resnet,
        "EfficientNet": build_efficientnet,
        "ConvNeXt": build_convnext,
        "CoAtNet": build_coatnet, 
        "Hybrid ViT": build_hybrid_vit
    }
    
    with st.spinner('Loading models from Hugging Face...'):
        for model_name, build_func in model_builders.items():
            try:
                model = build_func(NUM_CLASSES)
                
                checkpoint_filename = f"{model_name.lower().replace(' ', '_')}_best_acc.pth"
                
                try:
                    cache_dir = os.path.join(os.getcwd(), ".model_cache")
                    os.makedirs(cache_dir, exist_ok=True)
                    
                    checkpoint_path = hf_hub_download(
                        repo_id=HF_REPO_ID,
                        filename=checkpoint_filename,
                        cache_dir=cache_dir
                    )
                    
                    model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))
                except Exception as e:
                    st.error(f"Failed to download model from Hugging Face: {e}")
                    continue
                
                model = model.to(DEVICE)
                model.eval()
                
                models[model_name] = model
                st.success(f"‚úÖ Loaded {model_name} model")
            except Exception as e:
                st.error(f"‚ùå Failed to load {model_name} model: {e}")
    
    return models

def preprocess_image(image):
    """Preprocess the input image for model prediction"""
    transform = transforms.Compose([
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    
    image_tensor = transform(image).unsqueeze(0)
    return image_tensor.to(DEVICE)

def predict(image, models):
    """Run inference on the image with all models"""
    results = {}
    
    image_tensor = preprocess_image(image)
    
    for model_name, model in models.items():
        start_time = time.time()
        
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = F.softmax(outputs, dim=1)[0]
            prediction = torch.argmax(probabilities).item()
            confidence = probabilities[prediction].item() * 100
            
        inference_time = (time.time() - start_time) * 1000
        
        results[model_name] = {
            "prediction": prediction,
            "class_name": CLASSES[prediction],
            "confidence": confidence,
            "inference_time": inference_time
        }
    
    return results

def main():
    st.title("üñºÔ∏è AI vs Real Image Classifier")
    
    st.markdown("""
    ### Upload an image to determine if it's real or AI-generated
    
    This application uses five different deep learning models to classify whether an image is a real photograph 
    or generated by AI. Each model provides its own prediction and confidence score.
    """)
    
    if 'models' not in st.session_state:
        st.session_state.models = load_models()
        
    models = st.session_state.models
    
    if len(models) < 5:
        missing_models = set(["ResNet", "EfficientNet", "ConvNeXt", "CoAtNet", "Hybrid ViT"]) - set(models.keys())
        st.warning(f"‚ö†Ô∏è Some models failed to load: {', '.join(missing_models)}")
        
        if len(models) == 0:
            st.error("""
            No models could be loaded from Hugging Face. Please check:
            1. You've uploaded models to Hugging Face
            2. You've updated the HF_REPO_ID variable with your username
            3. The repository is public or you've set the correct tokens
            """)
    
    st.subheader("Upload an Image")
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
    
    col1, col2 = st.columns([1, 2])
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        with col1:
            st.image(image, caption="Uploaded Image", use_column_width=True)
        
        if st.button("Classify Image"):
            with st.spinner("Classifying..."):
                results = predict(image, models)
                
                with col2:
                    st.subheader("Model Predictions")
                    
                    model_names = []
                    confidences_real = []
                    confidences_ai = []
                    prediction_texts = []
                    inference_times = []
                    
                    for model_name, result in results.items():
                        model_names.append(model_name)
                        pred = result["prediction"]
                        conf = result["confidence"]
                        inf_time = result["inference_time"]
                        
                        if pred == 0:
                            confidences_real.append(conf)
                            confidences_ai.append(100 - conf)
                        else:
                            confidences_real.append(100 - conf)
                            confidences_ai.append(conf)
                        
                        pred_text = f"{result['class_name']} ({conf:.2f}%)"
                        prediction_texts.append(pred_text)
                        inference_times.append(f"{inf_time:.2f}ms")
                    
                    prediction_df = {
                        "Model": model_names,
                        "Prediction": prediction_texts,
                        "Inference Time": inference_times
                    }
                    
                    st.table(prediction_df)
                    
                    import altair as alt
                    import pandas as pd
                    
                    chart_data = pd.DataFrame({
                        "Model": model_names + model_names,
                        "Confidence": confidences_real + confidences_ai,
                        "Class": ["Real Image"] * len(model_names) + ["AI-Generated Image"] * len(model_names),
                        "Order": [1] * len(model_names) + [2] * len(model_names)
                    })
                    
                    chart = alt.Chart(chart_data).mark_bar().encode(
                        x=alt.X("Confidence:Q", title="Confidence (%)"),
                        y=alt.Y("Model:N", title="Model"),
                        color=alt.Color("Class:N", scale=alt.Scale(
                            domain=["Real Image", "AI-Generated Image"],
                            range=["#1f77b4", "#ff7f0e"]
                        )),
                        order="Order:Q",
                        tooltip=["Model", "Class", "Confidence"]
                    ).properties(
                        title="Confidence Scores by Model",
                        height=300
                    )
                    
                    st.altair_chart(chart, use_container_width=True)
                    
                    ensemble_votes = {0: 0, 1: 0}
                    for result in results.values():
                        ensemble_votes[result["prediction"]] += 1
                    
                    majority_class = 0 if ensemble_votes[0] > ensemble_votes[1] else 1
                    majority_vote_count = ensemble_votes[majority_class]
                    
                    st.subheader("Ensemble Prediction")
                    st.markdown(f"""
                    **Majority Vote**: {CLASSES[majority_class]} ({majority_vote_count}/5 models)
                    """)
    else:
        with col2:
            st.info("Please upload an image to get predictions.")
    
    with st.expander("About the Models"):
        st.markdown("""
        ### Model Information
        
        This application uses 5 different deep learning architectures:
        
        1. **ResNet-50**: A classic CNN architecture with skip connections to allow training of very deep networks.
        
        2. **EfficientNet-B4**: Optimized CNN known for efficiency and accuracy, using compound scaling.
        
        3. **ConvNeXt**: Modern CNN architecture inspired by Vision Transformers, with depthwise convolutions.
        
        4. **CoAtNet**: Hybrid model combining convolution and self-attention mechanisms.
        
        5. **Hybrid ViT**: Combines a ResNet feature extractor with Vision Transformer layers.
        
        Each model has been trained to distinguish between real photographs and AI-generated images.
        """)

if __name__ == "__main__":
    main()